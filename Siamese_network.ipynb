{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7396067,
          "sourceType": "datasetVersion",
          "datasetId": 4300202
        },
        {
          "sourceId": 7397096,
          "sourceType": "datasetVersion",
          "datasetId": 4300927
        },
        {
          "sourceId": 7397105,
          "sourceType": "datasetVersion",
          "datasetId": 4300932
        }
      ],
      "dockerImageVersionId": 30635,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "TxUh5c_8mr0_",
        "execution": {
          "iopub.status.busy": "2024-01-13T16:25:09.819775Z",
          "iopub.execute_input": "2024-01-13T16:25:09.820782Z",
          "iopub.status.idle": "2024-01-13T16:25:23.032744Z",
          "shell.execute_reply.started": "2024-01-13T16:25:09.820744Z",
          "shell.execute_reply": "2024-01-13T16:25:23.031668Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Libraries\n"
      ],
      "metadata": {
        "id": "d-TGRqzz3XQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "nJ97sa2KMJFl",
        "execution": {
          "iopub.status.busy": "2024-01-13T16:25:01.555513Z",
          "iopub.execute_input": "2024-01-13T16:25:01.556129Z",
          "iopub.status.idle": "2024-01-13T16:25:07.207111Z",
          "shell.execute_reply.started": "2024-01-13T16:25:01.556096Z",
          "shell.execute_reply": "2024-01-13T16:25:07.206076Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Summary"
      ],
      "metadata": {
        "id": "Rr_HyYQM3nNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/original_train.csv\")    # original training set from organizers\n",
        "test_df = pd.read_csv(\"/content/original_test.csv\")      # original test set from organizers\n",
        "dev_df = pd.read_csv(\"/content/original_dev.csv\")        # original dev set from organizers"
      ],
      "metadata": {
        "id": "AfTszcvR3xth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_long_text_summary(long_text, max_length_per_section):\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to('cuda')\n",
        "\n",
        "    # Split the text into smaller sections\n",
        "    sections = [long_text[i:i + max_length_per_section] for i in range(0, len(long_text), max_length_per_section)]\n",
        "\n",
        "    summaries = []\n",
        "\n",
        "    for section in sections:\n",
        "        input_text = \"summarize: \" + section\n",
        "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1000, truncation=True, padding=True)\n",
        "\n",
        "        # Adjust max_length and length_penalty as needed\n",
        "        summary_ids = model.generate(inputs.to('cuda'), max_length=100, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        summaries.append(summary)\n",
        "\n",
        "    # Concatenate the summaries for each section\n",
        "    final_summary = \" \".join(summaries)\n",
        "    return final_summary"
      ],
      "metadata": {
        "id": "8fNgvaalND8c",
        "execution": {
          "iopub.status.busy": "2024-01-13T16:25:33.230360Z",
          "iopub.execute_input": "2024-01-13T16:25:33.231167Z",
          "iopub.status.idle": "2024-01-13T16:25:33.240226Z",
          "shell.execute_reply.started": "2024-01-13T16:25:33.231130Z",
          "shell.execute_reply": "2024-01-13T16:25:33.238925Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_double_summary(df):\n",
        "    # Iterate through each row and generate summaries\n",
        "    for index, row in df.iterrows():\n",
        "        try:\n",
        "          input_text = row['explanation']\n",
        "\n",
        "          # Generate the first summary\n",
        "          summary = generate_long_text_summary(input_text, 1000)\n",
        "\n",
        "          # Use the first summary as input for the second summary\n",
        "          input_text = summary\n",
        "          summary_new = generate_long_text_summary(input_text, 300)\n",
        "\n",
        "          # Store the final summary in the 'summary' column\n",
        "          df.at[index, 'summary'] = summary_new\n",
        "        except:\n",
        "          df.at[index, 'summary'] = \" \"\n",
        "    return df"
      ],
      "metadata": {
        "id": "NSGne4D5M-rk",
        "execution": {
          "iopub.status.busy": "2024-01-13T16:25:52.285957Z",
          "iopub.execute_input": "2024-01-13T16:25:52.286851Z",
          "iopub.status.idle": "2024-01-13T18:22:59.799991Z",
          "shell.execute_reply.started": "2024-01-13T16:25:52.286815Z",
          "shell.execute_reply": "2024-01-13T18:22:59.799145Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 2nd level summary on all 3 sets\n",
        "df_train = generate_double_summary(train_df)\n",
        "df_test = generate_double_summary(test_df)\n",
        "df_dev = generate_double_summary(dev_df)\n",
        "\n",
        "# Save all 3 dataframes\n",
        "df_train.to_csv(\"/content/summary_train.csv\")\n",
        "df_test.to_csv(\"/content/summary_test.csv\")\n",
        "df_dev.to_csv(\"/content/summary_dev.csv\")"
      ],
      "metadata": {
        "id": "cAGXSfaG39tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev = pd.read_csv(\"/content/summary_dev.csv\") # Summarized Dev set\n",
        "df_train = pd.read_csv(\"/content/summary_train.csv\") # Summarized Train set\n",
        "df_test = pd.read_csv(\"/content/summary_test.csv\") # Summarized Test set"
      ],
      "metadata": {
        "id": "L7Q5U-gE37HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract embeddings using transformer"
      ],
      "metadata": {
        "id": "uJkqwf8-3_Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'LambdaX-AI/legal-deberta-v1'  # You can choose a different BERT model if needed\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name).to('cuda')"
      ],
      "metadata": {
        "id": "fTFMqe6jYZQK",
        "execution": {
          "iopub.status.busy": "2024-01-13T20:59:39.335355Z",
          "iopub.execute_input": "2024-01-13T20:59:39.335732Z",
          "iopub.status.idle": "2024-01-13T20:59:49.569228Z",
          "shell.execute_reply.started": "2024-01-13T20:59:39.335702Z",
          "shell.execute_reply": "2024-01-13T20:59:49.568155Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    inputs = inputs.to('cuda')\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().cpu().numpy()\n",
        "    return embeddings\n",
        "\n",
        "# Get embeddings for questions and answers\n",
        "df_train['question_embeddings'] = df_train['question'].apply(get_embeddings)\n",
        "df_train['answer_embeddings'] = df_train['answer'].apply(get_embeddings)\n",
        "df_train['summary_embeddings'] = df_train['summary'].apply(get_embeddings)\n"
      ],
      "metadata": {
        "id": "4q_3MGe6ap9S",
        "execution": {
          "iopub.status.busy": "2024-01-13T20:59:52.925511Z",
          "iopub.execute_input": "2024-01-13T20:59:52.926079Z",
          "iopub.status.idle": "2024-01-13T21:00:24.433713Z",
          "shell.execute_reply.started": "2024-01-13T20:59:52.926049Z",
          "shell.execute_reply": "2024-01-13T21:00:24.432925Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev['question_embeddings'] = df_dev['question'].apply(get_embeddings)\n",
        "df_dev['answer_embeddings'] = df_dev['answer'].apply(get_embeddings)\n",
        "df_dev['summary_embeddings'] = df_dev['summary'].apply(get_embeddings)"
      ],
      "metadata": {
        "id": "Ge0HAuu-RMXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['question_embeddings'] = df_test['question'].apply(get_embeddings)\n",
        "df_test['answer_embeddings'] = df_test['answer'].apply(get_embeddings)\n",
        "df_test['summary_embeddings'] = df_test['summary'].apply(get_embeddings)"
      ],
      "metadata": {
        "id": "oUA9OOEjOIA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qe_train= torch.tensor(df_train['question_embeddings'].tolist(), dtype=torch.float32)\n",
        "ae_train= torch.tensor(df_train['answer_embeddings'].tolist(), dtype=torch.float32)\n",
        "se_train= torch.tensor(df_train['summary_embeddings'].tolist(), dtype=torch.float32)\n",
        "\n",
        "qe_dev= torch.tensor(df_dev['question_embeddings'].tolist(), dtype=torch.float32)\n",
        "ae_dev= torch.tensor(df_dev['answer_embeddings'].tolist(), dtype=torch.float32)\n",
        "se_dev= torch.tensor(df_dev['summary_embeddings'].tolist(), dtype=torch.float32)\n",
        "\n",
        "qe_test= torch.tensor(df_test['question_embeddings'].tolist(), dtype=torch.float32)\n",
        "ae_test= torch.tensor(df_test['answer_embeddings'].tolist(), dtype=torch.float32)\n",
        "se_test= torch.tensor(df_test['summary_embeddings'].tolist(), dtype=torch.float32)"
      ],
      "metadata": {
        "id": "aj3kXNKCwMbX",
        "execution": {
          "iopub.status.busy": "2024-01-13T21:00:37.505543Z",
          "iopub.execute_input": "2024-01-13T21:00:37.506407Z",
          "iopub.status.idle": "2024-01-13T21:00:37.922254Z",
          "shell.execute_reply.started": "2024-01-13T21:00:37.506369Z",
          "shell.execute_reply": "2024-01-13T21:00:37.921313Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_train = torch.FloatTensor(df_train['label'])\n",
        "labels_dev = torch.FloatTensor(df_dev['label'])\n",
        "\n",
        "question_train_tensor = torch.FloatTensor(qe_train)\n",
        "answer_train_tensor = torch.FloatTensor(ae_train)\n",
        "summary_train_tensor = torch.FloatTensor(se_train)\n",
        "labels_train_tensor = torch.FloatTensor(labels_train)\n",
        "\n",
        "question_test_tensor = torch.FloatTensor(qe_test)\n",
        "answer_test_tensor = torch.FloatTensor(ae_test)\n",
        "summary_test_tensor = torch.FloatTensor(se_test)\n",
        "\n",
        "question_dev_tensor = torch.FloatTensor(qe_dev)\n",
        "answer_dev_tensor = torch.FloatTensor(ae_dev)\n",
        "summary_dev_tensor = torch.FloatTensor(se_dev)\n",
        "labels_dev_tensor = torch.FloatTensor(labels_dev)"
      ],
      "metadata": {
        "id": "VqitQl5c5Wnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to train Siamese Network"
      ],
      "metadata": {
        "id": "boskzZ4a4woy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Siamese Network\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, embedding_size):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        # Define three branches for question, answer, and summary\n",
        "        self.branch_question = nn.Sequential(\n",
        "            nn.Linear(embedding_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.branch_answer = nn.Sequential(\n",
        "            nn.Linear(embedding_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.branch_summary = nn.Sequential(\n",
        "            nn.Linear(embedding_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Final linear layer for computing similarity\n",
        "        self.fc = nn.Linear(256*3, 1)\n",
        "\n",
        "    def forward_one_branch(self, x, branch):\n",
        "        # Forward pass for a single branch\n",
        "        x = branch(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, question, answer, summary):\n",
        "        # Forward pass for each branch\n",
        "        output_question = self.forward_one_branch(question, self.branch_question)\n",
        "        output_answer = self.forward_one_branch(answer, self.branch_answer)\n",
        "        output_summary = self.forward_one_branch(summary, self.branch_summary)\n",
        "\n",
        "        # Concatenate outputs from three branches\n",
        "        concatenated = torch.cat((output_question, output_answer, output_summary), 1)\n",
        "\n",
        "        # Final linear layer to compute similarity\n",
        "        similarity_score = torch.sigmoid(self.fc(concatenated))\n",
        "\n",
        "        return similarity_score\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_siamese_network(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for question, answer, summary, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(question, answer, summary)\n",
        "            loss = criterion(outputs, labels.unsqueeze(1).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "kvXP08IMyURo",
        "execution": {
          "iopub.status.busy": "2024-01-13T21:13:05.056553Z",
          "iopub.execute_input": "2024-01-13T21:13:05.056924Z",
          "iopub.status.idle": "2024-01-13T21:13:05.073662Z",
          "shell.execute_reply.started": "2024-01-13T21:13:05.056891Z",
          "shell.execute_reply": "2024-01-13T21:13:05.072802Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataLoader for training and testing\n",
        "train_dataset = TensorDataset(question_train_tensor, answer_train_tensor, summary_train_tensor, labels_train_tensor)\n",
        "test_dataset = TensorDataset(question_test_tensor, answer_test_tensor, summary_test_tensor)\n",
        "dev_dataset = TensorDataset(question_dev_tensor, answer_dev_tensor, summary_dev_tensor, labels_dev_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Create and initialize the Siamese network\n",
        "embedding_size = 1536  # Adjust according to your embedding size\n",
        "siamese_model = SiameseNetwork(embedding_size)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(siamese_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the Siamese network\n",
        "train_siamese_network(siamese_model, train_loader, criterion, optimizer, 20)\n"
      ],
      "metadata": {
        "id": "1-tql2Xl9hNU",
        "execution": {
          "iopub.status.busy": "2024-01-13T21:13:08.380760Z",
          "iopub.execute_input": "2024-01-13T21:13:08.381652Z",
          "iopub.status.idle": "2024-01-13T21:13:14.987290Z",
          "shell.execute_reply.started": "2024-01-13T21:13:08.381596Z",
          "shell.execute_reply": "2024-01-13T21:13:14.986369Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to test Siamese Network\n"
      ],
      "metadata": {
        "id": "pIKR2td24_AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function\n",
        "def test_siamese_network(model, dev_loader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for question, answer, summary, labels in dev_loader:\n",
        "            outputs = model(question, answer, summary)\n",
        "            predicted = (outputs > 0.6).float().cpu().numpy()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted)\n",
        "\n",
        "    macro_f1 = f1_score(all_labels, all_predictions, average='macro')\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f'Test Macro F1 Score: {macro_f1:.4f}')\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "VePOcD665D0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to predict using siamese network"
      ],
      "metadata": {
        "id": "2-mPr6yM5GiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_siamese_network(model, test_loader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for question, answer, summary in test_loader:\n",
        "            outputs = model(question, answer, summary)\n",
        "            predicted = (outputs > 0.6).float().cpu().numpy()\n",
        "            all_predictions.extend(predicted)\n",
        "\n",
        "    return all_predictions"
      ],
      "metadata": {
        "id": "QCzLiS315LiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the Siamese network on dev set\n",
        "test_siamese_network(siamese_model, dev_loader)"
      ],
      "metadata": {
        "id": "6NuHo3w-Pzk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions of Siamese network on test set\n",
        "predictions = predict_siamese_network(siamese_model, test_loader)\n",
        "predictions = np.array(predictions)\n",
        "y = pd.DataFrame({'predictions': np.squeeze(predictions)})"
      ],
      "metadata": {
        "id": "-q8mcxYcR5GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.to_csv(\"siamese.csv\", index=True)"
      ],
      "metadata": {
        "id": "axCDNdUThRYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "            'model_state_dict': siamese_model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'embedding_size': embedding_size\n",
        "            }, 'siamese_model.pth')"
      ],
      "metadata": {
        "id": "P51jsffdhZXm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}